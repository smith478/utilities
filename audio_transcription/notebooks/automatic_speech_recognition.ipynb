{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a6f03b-0ec3-443a-947f-d6b8b44682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.signal import resample\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c1845-73ee-457a-9233-d775eac5fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e411903-6dd5-427b-89da-78c2b1628f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932eb0c-92c7-4e74-9deb-e5416f0eb40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10649025-194d-462e-bee6-5dc988de2380",
   "metadata": {},
   "source": [
    "## Load audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f284595-a273-4010-a2cc-c8fa7c525296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the audio file and get the sample rate and audio data\n",
    "sample_rate, audio_data = wavfile.read(f'../artifacts/e9566c13-b385-46c1-b794-d8f419628aff.wav')\n",
    "\n",
    "# Ensure audio data is within range for int16\n",
    "audio_data = np.clip(audio_data, -32768, 32767).astype(np.int16)\n",
    "\n",
    "# audio_data is now a NumPy array containing the audio samples\n",
    "# sample_rate contains the sample rate of the audio file\n",
    "\n",
    "# You can perform operations on the audio data as needed\n",
    "# For example, you can print the length of the audio in seconds:\n",
    "audio_length_seconds = len(audio_data) / sample_rate\n",
    "print(f\"Audio Length: {audio_length_seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929d6f60-d4b8-407c-8cbe-ed9fe8c7a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a74864-7a71-434f-a45d-a73948d5dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(audio_data.T, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5282ce-3228-4f80-8498-9491ae63cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target sample rate (16,000 Hz)\n",
    "target_sample_rate = 16000\n",
    "\n",
    "# Calculate the resampling factor\n",
    "resampling_factor = target_sample_rate / sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9f88b-32b9-4b89-b1cf-d6493fd47b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the audio data\n",
    "resampled_audio_data = resample(audio_data, int(len(audio_data) * resampling_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46d083-4074-4761-a0b0-d3a288c3c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(resampled_audio_data.T, rate=target_sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962a95e6-55b0-4d26-8e6a-03ec3c99208f",
   "metadata": {},
   "source": [
    "## Load Phi 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e618a54b-d434-4fcf-91b7-d251b280b820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066db4d-21c2-40f3-9e58-1c4918a1b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'openai/whisper-large-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5985f8-fba2-4db7-a45c-0b4fa7fcd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(f'../models/{model_id}')\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41316fab-54d2-41fa-a288-015f2db76b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = processor(resampled_audio_data.T, \n",
    "                         return_tensors=\"pt\",\n",
    "                         sampling_rate=target_sample_rate\n",
    "                        ).input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4be7c6-62c2-49fc-babd-1064f3a5aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = model.generate(input_values)\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64695ab2-7e7a-49e4-9871-2a4b5c093698",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
