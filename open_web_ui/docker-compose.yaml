version: "3.8"

services:
  open-webui:
    build: .
    ports:
      - "3000:8080"
    environment:
      LLAMAINDEX_MODEL_NAME: "llama3.2"  # Default model
      LLAMAINDEX_EMBEDDING_MODEL_NAME: "nomic-embed-text" # bge-large or granite-embedding
    volumes:
      - open-webui:/app/backend/data
      - ./pubmed_rag.py:/app/backend/pipelines/pubmed_rag.py  # Mount custom pipeline

volumes:
  open-webui: