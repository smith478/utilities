{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3888fc6f-592a-4454-9ccf-1c643c3827ec",
   "metadata": {},
   "source": [
    "# Agentic RAG\n",
    "\n",
    "- Step 1: Use a base LLM to generate content in the style of an author\n",
    "- Step 2: Do this using RAG\n",
    "- Step 3: Do this using agentic RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a5b487-742b-4f25-a2b1-79501e51a15d",
   "metadata": {},
   "source": [
    "## Basic Retrieval with DuckDuckGo\n",
    "\n",
    "Let's build a simple agent that can search the web using DuckDuckGo. This agent will retrieve information and synthesize responses to answer queries. With Agentic RAG, our agent can:\n",
    "\n",
    "- Search for articles from an author\n",
    "- Refine results to include relevant pieces\n",
    "- Synthesize information into a take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f41750-2786-4f50-b611-a7bcb0d3c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool\n",
    "from smolagents.models import LiteLLMModel\n",
    "\n",
    "# Initialize the search tool\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "\n",
    "# Initialize the model\n",
    "local_model = LiteLLMModel(model_id=\"ollama_chat/qwen3:8b\")\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model = local_model,\n",
    "    tools=[search_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ce581-6d20-4939-a8f0-15166917b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR = \"Robert Wright\"\n",
    "HEADLINE = \"US Strikes Iran’s Nuclear Sites, Risking Wider War in Mideast\"\n",
    "STORY = \"\"\"\n",
    "The US carried out airstrikes on three nuclear sites in Iran overnight, directly entering Israel’s war with Tehran despite President Donald Trump’s longtime promises to avoid new foreign conflicts.\n",
    "Trump said Iran’s key nuclear enrichment facilities had been “totally obliterated” and warned of “far greater” attacks unless the Islamic Republic agreed to make peace, raising the prospect of deeper US involvement in a Middle East war sparked by Israeli strikes nine days ago.\n",
    "Iranian officials said the ongoing attacks by Israel — now joined by the US — had left little room for diplomacy, arguing that negotiations are impossible while the country is under assault. Tehran fired missiles at Israel in response but has so far stopped short of targeting American forces or assets in the region.\n",
    "American B-2 bombers dropped a dozen of the 30,000-pound (13,600-kilogram) bunker-buster bombs on Fordow, a uranium-enrichment site buried deep under a mountain, the New York Times reported. Natanz and Isfahan, two other nuclear facilities, were also struck using similar weapons and cruise missiles.\n",
    "“Our objective was the destruction of Iran’s nuclear enrichment capacity and a stop to the nuclear threat posed by the world’s No. 1 state sponsor of terror,” Trump said. “Iran, the bully of the Middle East, must now make peace. If they do not, future attacks will be far greater — and a lot easier.”\n",
    "Iran’s foreign minister, Abbas Araghchi, said the American strikes are “outrageous and will have everlasting consequences.” \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e7c84d-13aa-41a0-891e-d04b3bd92d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Use the following news headline and story to generate an output or take that you think would most likely come from the author {AUTHOR}.\n",
    "Headline: {HEADLINE}\n",
    "Story: {STORY}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda03e77-02f9-4386-a735-6b17017cedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.run(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6531cd-13fc-4299-89f0-a91f9efc99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, Tool\n",
    "from smolagents.models import LiteLLMModel\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "# RTF file reader utility\n",
    "def read_rtf_file(file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple RTF reader that extracts plain text from RTF files.\n",
    "    For production use, consider using python-rtf or striprtf libraries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Basic RTF cleaning - remove RTF control codes\n",
    "        # This is a simplified approach; for complex RTF files, use dedicated libraries\n",
    "        content = re.sub(r'\\\\[a-z]+\\d*', '', content)  # Remove RTF commands\n",
    "        content = re.sub(r'[{}]', '', content)  # Remove braces\n",
    "        content = re.sub(r'\\s+', ' ', content)  # Normalize whitespace\n",
    "        content = content.strip()\n",
    "        \n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading RTF file {file_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Step 1: Base LLM Content Generation\n",
    "class BaseAuthorGenerator:\n",
    "    \"\"\"Step 1: Basic author style generation without RAG\"\"\"\n",
    "    \n",
    "    def __init__(self, author_name: str, model_id: str = \"ollama_chat/qwen3:8b\"):\n",
    "        self.author_name = author_name\n",
    "        self.model = LiteLLMModel(model_id=model_id)\n",
    "        self.agent = CodeAgent(model=self.model, tools=[])\n",
    "    \n",
    "    def generate_response(self, headline: str, story: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        You are tasked with generating content in the style of {self.author_name}.\n",
    "        \n",
    "        Based on the following news headline and story, create a response or commentary \n",
    "        that captures {self.author_name}'s distinctive voice, perspective, and style.\n",
    "        \n",
    "        Headline: {headline}\n",
    "        Story: {story}\n",
    "        \n",
    "        Generate a response that {self.author_name} would likely write:\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.agent.run(prompt)\n",
    "\n",
    "# Step 2: RAG-Enhanced Author Generator\n",
    "class AuthorDocumentRetrieverTool(Tool):\n",
    "    \"\"\"Custom retriever tool for author's documents\"\"\"\n",
    "    \n",
    "    name = \"author_document_retriever\"\n",
    "    description = \"Retrieves relevant passages from the author's existing works to inform style and content generation.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to search for relevant content in the author's documents.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs: List[Document], **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=3  # Retrieve top 3 most relevant passages\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "        \n",
    "        docs = self.retriever.invoke(query)\n",
    "        \n",
    "        if not docs:\n",
    "            return \"No relevant passages found in the author's documents.\"\n",
    "        \n",
    "        result = \"\\n=== RELEVANT AUTHOR PASSAGES ===\\n\"\n",
    "        for i, doc in enumerate(docs, 1):\n",
    "            result += f\"\\n--- Passage {i} ---\\n{doc.page_content}\\n\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "class RAGAuthorGenerator:\n",
    "    \"\"\"Step 2: RAG-enhanced author style generation\"\"\"\n",
    "    \n",
    "    def __init__(self, author_name: str, rtf_documents_path: str, model_id: str = \"ollama_chat/qwen3:8b\"):\n",
    "        self.author_name = author_name\n",
    "        self.model = LiteLLMModel(model_id=model_id)\n",
    "        \n",
    "        # Load and process author's documents\n",
    "        self.documents = self._load_author_documents(rtf_documents_path)\n",
    "        \n",
    "        # Create retriever tool\n",
    "        self.retriever_tool = AuthorDocumentRetrieverTool(self.documents)\n",
    "        \n",
    "        # Initialize agent with retriever\n",
    "        self.agent = CodeAgent(\n",
    "            model=self.model,\n",
    "            tools=[self.retriever_tool]\n",
    "        )\n",
    "    \n",
    "    def _load_author_documents(self, documents_path: str) -> List[Document]:\n",
    "        \"\"\"Load and process RTF documents from the specified path\"\"\"\n",
    "        documents = []\n",
    "        path = Path(documents_path)\n",
    "        \n",
    "        if not path.exists():\n",
    "            print(f\"Warning: Path {documents_path} does not exist. Creating empty document set.\")\n",
    "            return documents\n",
    "        \n",
    "        # Process RTF files\n",
    "        for rtf_file in path.glob(\"*.rtf\"):\n",
    "            content = read_rtf_file(str(rtf_file))\n",
    "            if content:\n",
    "                documents.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\"source\": rtf_file.name, \"file_path\": str(rtf_file)}\n",
    "                ))\n",
    "        \n",
    "        # Split documents into chunks for better retrieval\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"],\n",
    "        )\n",
    "        \n",
    "        processed_docs = text_splitter.split_documents(documents)\n",
    "        print(f\"Loaded {len(documents)} documents, split into {len(processed_docs)} chunks\")\n",
    "        \n",
    "        return processed_docs\n",
    "    \n",
    "    def generate_response(self, headline: str, story: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        You are generating content in the style of {self.author_name}.\n",
    "        \n",
    "        First, use the author_document_retriever tool to find relevant passages from {self.author_name}'s \n",
    "        existing works that relate to the topic, themes, or style needed for this response.\n",
    "        \n",
    "        Search for passages related to: \"{headline}\"\n",
    "        \n",
    "        Then, based on the retrieved passages and the following news content, generate a response \n",
    "        that authentically captures {self.author_name}'s voice, style, and perspective:\n",
    "        \n",
    "        Headline: {headline}\n",
    "        Story: {story}\n",
    "        \n",
    "        Make sure to incorporate the stylistic elements and thematic approaches found in the retrieved passages.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.agent.run(prompt)\n",
    "\n",
    "# Step 3: Advanced Agentic RAG with Multiple Tools\n",
    "class AdvancedAgenticRAG:\n",
    "    \"\"\"Step 3: Full agentic RAG with multiple tools and sophisticated reasoning\"\"\"\n",
    "    \n",
    "    def __init__(self, author_name: str, rtf_documents_path: str, model_id: str = \"ollama_chat/qwen3:8b\"):\n",
    "        self.author_name = author_name\n",
    "        self.model = LiteLLMModel(model_id=model_id)\n",
    "        \n",
    "        # Load author documents\n",
    "        self.documents = self._load_author_documents(rtf_documents_path)\n",
    "        \n",
    "        # Initialize tools\n",
    "        self.retriever_tool = AuthorDocumentRetrieverTool(self.documents)\n",
    "        self.search_tool = DuckDuckGoSearchTool()\n",
    "        \n",
    "        # Initialize agent with multiple tools\n",
    "        self.agent = CodeAgent(\n",
    "            model=self.model,\n",
    "            tools=[self.retriever_tool, self.search_tool]\n",
    "        )\n",
    "    \n",
    "    def _load_author_documents(self, documents_path: str) -> List[Document]:\n",
    "        \"\"\"Load and process RTF documents\"\"\"\n",
    "        documents = []\n",
    "        path = Path(documents_path)\n",
    "        \n",
    "        if not path.exists():\n",
    "            print(f\"Warning: Path {documents_path} does not exist. Creating empty document set.\")\n",
    "            return documents\n",
    "        \n",
    "        for rtf_file in path.glob(\"*.rtf\"):\n",
    "            content = read_rtf_file(str(rtf_file))\n",
    "            if content:\n",
    "                documents.append(Document(\n",
    "                    page_content=content,\n",
    "                    metadata={\"source\": rtf_file.name, \"file_path\": str(rtf_file)}\n",
    "                ))\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=100,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"],\n",
    "        )\n",
    "        \n",
    "        processed_docs = text_splitter.split_documents(documents)\n",
    "        print(f\"Loaded {len(documents)} documents, split into {len(processed_docs)} chunks\")\n",
    "        \n",
    "        return processed_docs\n",
    "    \n",
    "    def generate_response(self, headline: str, story: str) -> str:\n",
    "        prompt = f\"\"\"\n",
    "        You are an expert at generating content in the authentic style of {self.author_name}.\n",
    "        \n",
    "        Your task is to create a thoughtful response to the following news story that captures \n",
    "        {self.author_name}'s distinctive voice, analytical approach, and perspective.\n",
    "        \n",
    "        To do this effectively, you should:\n",
    "        \n",
    "        1. First, use the author_document_retriever tool to find relevant passages from {self.author_name}'s \n",
    "           existing works that relate to the themes, topics, or issues in this news story.\n",
    "        \n",
    "        2. If you need additional context or recent information about the topic, use the duckduckgo_search \n",
    "           tool to gather more current information.\n",
    "        \n",
    "        3. Analyze the retrieved content to identify key stylistic elements, argumentative patterns, \n",
    "           and thematic approaches that characterize {self.author_name}'s work.\n",
    "        \n",
    "        4. Generate a response that authentically reflects {self.author_name}'s voice while addressing \n",
    "           the current news story.\n",
    "        \n",
    "        News to respond to:\n",
    "        Headline: {headline}\n",
    "        Story: {story}\n",
    "        \n",
    "        Create a response that {self.author_name} would likely write, incorporating their distinctive \n",
    "        style, perspective, and approach to similar topics based on their existing work.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.agent.run(prompt)\n",
    "\n",
    "# Example usage and testing\n",
    "def main():\n",
    "    # Configuration\n",
    "    AUTHOR = \"Your Author Name\"  # Replace with actual author name\n",
    "    HEADLINE = \"Tech Giants Announce New AI Regulations\"  # Replace with actual headline\n",
    "    STORY = \"Major technology companies have agreed to new self-imposed regulations...\"  # Replace with actual story\n",
    "    RTF_DOCUMENTS_PATH = \"./author_documents\"  # Path to your RTF files\n",
    "    \n",
    "    print(\"=== AGENTIC RAG PROGRESSION ===\\n\")\n",
    "    \n",
    "    # Step 1: Base LLM Generation\n",
    "    print(\"STEP 1: Base LLM Content Generation\")\n",
    "    print(\"-\" * 40)\n",
    "    base_generator = BaseAuthorGenerator(AUTHOR)\n",
    "    step1_response = base_generator.generate_response(HEADLINE, STORY)\n",
    "    print(f\"Response: {step1_response}\\n\")\n",
    "    \n",
    "    # Step 2: RAG-Enhanced Generation\n",
    "    print(\"STEP 2: RAG-Enhanced Generation\")\n",
    "    print(\"-\" * 40)\n",
    "    rag_generator = RAGAuthorGenerator(AUTHOR, RTF_DOCUMENTS_PATH)\n",
    "    step2_response = rag_generator.generate_response(HEADLINE, STORY)\n",
    "    print(f\"Response: {step2_response}\\n\")\n",
    "    \n",
    "    # Step 3: Advanced Agentic RAG\n",
    "    print(\"STEP 3: Advanced Agentic RAG\")\n",
    "    print(\"-\" * 40)\n",
    "    advanced_rag = AdvancedAgenticRAG(AUTHOR, RTF_DOCUMENTS_PATH)\n",
    "    step3_response = advanced_rag.generate_response(HEADLINE, STORY)\n",
    "    print(f\"Response: {step3_response}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
